{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model: Version 4\n",
    "Uses logisitic regression to test out these models along with v2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "#Import other files\n",
    "raw_path = os.path.join('..', 'data', 'raw')\n",
    "proc_path = os.path.join('..', 'data', 'processed')\n",
    "sys.path.append(os.path.join('..', 'src'))\n",
    "from model.Log_Model import *\n",
    "from model.Scoring import *\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in data\n",
    "ss_v1 = pd.read_csv(os.path.join(proc_path, 'scoring_set_v1.csv'))\n",
    "ss_v2 = pd.read_csv(os.path.join(proc_path, 'scoring_set_v2.csv'))\n",
    "ss_v3 = pd.read_csv(os.path.join(proc_path, 'scoring_set_v3.csv'))\n",
    "\n",
    "# Reads in data\n",
    "seeds = pd.read_csv(os.path.join(raw_path, 'TourneySeeds.csv'))\n",
    "slots = pd.read_csv(os.path.join(raw_path, 'TourneySlots.csv'))\n",
    "results = pd.read_csv(os.path.join(raw_path, 'TourneyCompactResults.csv'))\n",
    "features = pd.read_csv(os.path.join(proc_path, 'team_features_v2.csv'))\n",
    "\n",
    "seeds = seeds[seeds['Season']>2003]\n",
    "slots = slots[slots['Season']>2003]\n",
    "results = results[results['Season']>2003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preps file for model\n",
    "x = ss_v1.drop(['Outcome', 'Team_A', 'Team_B'], 1)\n",
    "y = [1 if a>0 else 0 for a in ss_v1['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.7\n",
      "Avg Pts 81.8461538462\n",
      "lr\n",
      "0.688235294118\n",
      "Avg Pts 81.8461538462\n",
      "lr\n",
      "0.708235294118\n",
      "Avg Pts 75.4615384615\n"
     ]
    }
   ],
   "source": [
    "#Creates model\n",
    "game_model = Log_Model()\n",
    "game_model.set_training(x,y)\n",
    "game_model.calc_model()\n",
    "print game_model.get_model_type()\n",
    "print game_model.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer = Scorer(features)\n",
    "scorer.set_variables(slots, seeds, results, game_model)\n",
    "print 'Avg Pts', scorer.score_model()\n",
    "\n",
    "#Creates model with scaling\n",
    "game_model_s = Log_Model()\n",
    "game_model_s.set_training(x,y)\n",
    "game_model_s.set_pipeline([('scaler', RobustScaler())], None)\n",
    "game_model_s.calc_model()\n",
    "print game_model_s.get_model_type()\n",
    "print game_model_s.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_s = Scorer(features)\n",
    "scorer_s.set_variables(slots, seeds, results, game_model_s)\n",
    "print 'Avg Pts', scorer_s.score_model()\n",
    "\n",
    "#Creates model with feature selection\n",
    "game_model_f = Log_Model()\n",
    "game_model_f.set_training(x,y)\n",
    "steps = [('feature_selection', SelectKBest())]\n",
    "params = dict(feature_selection__k=[3,5,10])\n",
    "game_model_f.set_pipeline(steps, params)\n",
    "game_model_f.calc_model()\n",
    "print game_model_f.get_model_type()\n",
    "print game_model_f.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_f = Scorer(features)\n",
    "scorer_f.set_variables(slots, seeds, results, game_model_f)\n",
    "print 'Avg Pts', scorer_f.score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preps file for model\n",
    "x = ss_v2.drop(['Team_A', 'Team_B', 'Outcome'], 1)\n",
    "                \n",
    "#drops variables that were used in cluster\n",
    "x = x.drop(['total_poss_A', 'total_poss_B', 'oeff_A', 'oeff_B', 'deff_A', 'deff_B'], 1)\n",
    "y = [1 if a>0 else 0 for a in ss_v2['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.702352941176\n",
      "Avg Pts 82.4615384615\n"
     ]
    }
   ],
   "source": [
    "#Creates model\n",
    "game_model = Log_Model()\n",
    "game_model.set_training(x,y)\n",
    "game_model.calc_model()\n",
    "print game_model.get_model_type()\n",
    "print game_model.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer = Scorer(features)\n",
    "scorer.set_variables(slots, seeds, results, game_model)\n",
    "print 'Avg Pts', scorer.score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.701176470588\n",
      "Avg Pts 82.5384615385\n"
     ]
    }
   ],
   "source": [
    "#Creates model with scaling\n",
    "game_model_s = Log_Model()\n",
    "game_model_s.set_training(x,y)\n",
    "game_model_s.set_pipeline([('scaler', RobustScaler())], None)\n",
    "game_model_s.calc_model()\n",
    "print game_model_s.get_model_type()\n",
    "print game_model_s.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_s = Scorer(features)\n",
    "scorer_s.set_variables(slots, seeds, results, game_model_s)\n",
    "print 'Avg Pts', scorer_s.score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.712941176471\n",
      "Avg Pts 72.4615384615\n"
     ]
    }
   ],
   "source": [
    "#Creates model with feature selection\n",
    "game_model_f = Log_Model()\n",
    "game_model_f.set_training(x,y)\n",
    "steps = [('feature_selection', SelectKBest())]\n",
    "params = dict(feature_selection__k=[3,5,10])\n",
    "game_model_f.set_pipeline(steps, params)\n",
    "game_model_f.calc_model()\n",
    "print game_model_f.get_model_type()\n",
    "print game_model_f.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_f = Scorer(features)\n",
    "scorer_f.set_variables(slots, seeds, results, game_model_f)\n",
    "print 'Avg Pts', scorer_f.score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.703529411765\n",
      "Avg Pts 72.7692307692\n"
     ]
    }
   ],
   "source": [
    "#Creates model with scaler and feature selection\n",
    "game_model_fs = Log_Model()\n",
    "game_model_fs.set_training(x,y)\n",
    "steps = [('scaler', RobustScaler()), ('feature_selection', SelectKBest())]\n",
    "params = dict(feature_selection__k=[3,5,10])\n",
    "game_model_fs.set_pipeline(steps, params)\n",
    "game_model_fs.calc_model()\n",
    "print game_model_fs.get_model_type()\n",
    "print game_model_fs.get_acc()\n",
    "\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_fs = Scorer(features)\n",
    "scorer_fs.set_variables(slots, seeds, results, game_model_fs)\n",
    "print 'Avg Pts', scorer_fs.score_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Makes interactions\n",
    "interactions = []\n",
    "for idx1 in range(3):\n",
    "    for idx2 in range(3):\n",
    "        interactions.append(('clstr_'+str(idx1)+'_A', 'clstr_'+str(idx2)+'_B'))\n",
    "interactions\n",
    "\n",
    "#Preps file for model\n",
    "x = ss_v3.drop(['Team_A', 'Team_B', 'Outcome'], 1)\n",
    "                \n",
    "#drops variables that were used in cluster\n",
    "x = x.drop(['total_poss_A', 'total_poss_B', 'oeff_A', 'oeff_B', 'deff_A', 'deff_B'], 1)\n",
    "x = x.drop(['clstr_0_A', 'clstr_0_B', 'clstr_1_A', 'clstr_1_B', 'clstr_2_A', 'clstr_2_B'], 1)\n",
    "y = [1 if a>0 else 0 for a in ss_v3['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.702352941176\n",
      "Avg Pts 81.2307692308\n",
      "lr\n",
      "0.709411764706\n",
      "Avg Pts 85.0769230769\n",
      "lr\n",
      "0.697647058824\n",
      "Avg Pts 79.7692307692\n"
     ]
    }
   ],
   "source": [
    "#Creates model\n",
    "game_model = Log_Model()\n",
    "game_model.set_training(x,y)\n",
    "game_model.calc_model()\n",
    "print game_model.get_model_type()\n",
    "print game_model.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer = Scorer(features)\n",
    "scorer.set_variables(slots, seeds, results, game_model)\n",
    "print 'Avg Pts', scorer.score_model(interactions)\n",
    "\n",
    "#Creates model with scaling\n",
    "game_model_s = Log_Model()\n",
    "game_model_s.set_training(x,y)\n",
    "game_model_s.set_pipeline([('scaler', RobustScaler())], None)\n",
    "game_model_s.calc_model()\n",
    "print game_model_s.get_model_type()\n",
    "print game_model_s.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_s = Scorer(features)\n",
    "scorer_s.set_variables(slots, seeds, results, game_model_s)\n",
    "print 'Avg Pts', scorer_s.score_model(interactions)\n",
    "\n",
    "#Creates model with feature selection\n",
    "game_model_f = Log_Model()\n",
    "game_model_f.set_training(x,y)\n",
    "steps = [('feature_selection', SelectKBest())]\n",
    "params = dict(feature_selection__k=[3,5,10])\n",
    "game_model_f.set_pipeline(steps, params)\n",
    "game_model_f.calc_model()\n",
    "print game_model_f.get_model_type()\n",
    "print game_model_f.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_f = Scorer(features)\n",
    "scorer_f.set_variables(slots, seeds, results, game_model_f)\n",
    "print 'Avg Pts', scorer_f.score_model(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pickles best model, which was ridge with feature selection\n",
    "import pickle\n",
    "fn = os.path.join(proc_path, 'Models', 'model_v4.p')\n",
    "pickle.dump(game_model_s, open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Makes interactions\n",
    "interactions = []\n",
    "for idx1 in range(3):\n",
    "    for idx2 in range(3):\n",
    "        interactions.append(('clstr_'+str(idx1)+'_A', 'clstr_'+str(idx2)+'_B'))\n",
    "interactions\n",
    "\n",
    "#Preps file for model\n",
    "x = ss_v3.drop(['Team_A', 'Team_B', 'Outcome'], 1)\n",
    "                \n",
    "#drops variables that were used in cluster\n",
    "x = x.drop(['total_poss_A', 'total_poss_B', 'oeff_A', 'oeff_B', 'deff_A', 'deff_B'], 1)\n",
    "# x = x.drop(['clstr_0_A', 'clstr_0_B', 'clstr_1_A', 'clstr_1_B', 'clstr_2_A', 'clstr_2_B'], 1)\n",
    "y = [1 if a>0 else 0 for a in ss_v3['Outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n",
      "0.702352941176\n",
      "Avg Pts 84.8461538462\n",
      "lr\n",
      "0.705882352941\n",
      "Avg Pts 84.8461538462\n",
      "svc_other\n",
      "0.701176470588\n",
      "Avg Pts 80.6153846154\n"
     ]
    }
   ],
   "source": [
    "#Creates model\n",
    "game_model = Log_Model()\n",
    "game_model.set_training(x,y)\n",
    "game_model.calc_model()\n",
    "print game_model.get_model_type()\n",
    "print game_model.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer = Scorer(features)\n",
    "scorer.set_variables(slots, seeds, results, game_model)\n",
    "print 'Avg Pts', scorer.score_model(interactions)\n",
    "\n",
    "#Creates model with scaling\n",
    "game_model_s = Log_Model()\n",
    "game_model_s.set_training(x,y)\n",
    "game_model_s.set_pipeline([('scaler', RobustScaler())], None)\n",
    "game_model_s.calc_model()\n",
    "print game_model_s.get_model_type()\n",
    "print game_model_s.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_s = Scorer(features)\n",
    "scorer_s.set_variables(slots, seeds, results, game_model_s)\n",
    "print 'Avg Pts', scorer_s.score_model(interactions)\n",
    "\n",
    "#Creates model with feature selection\n",
    "game_model_f = Log_Model()\n",
    "game_model_f.set_training(x,y)\n",
    "steps = [('feature_selection', SelectKBest())]\n",
    "params = dict(feature_selection__k=[3,5,10])\n",
    "game_model_f.set_pipeline(steps, params)\n",
    "game_model_f.calc_model()\n",
    "print game_model_f.get_model_type()\n",
    "print game_model_f.get_acc()\n",
    "\n",
    "#Scores in simulated tournament\n",
    "scorer_f = Scorer(features)\n",
    "scorer_f.set_variables(slots, seeds, results, game_model_f)\n",
    "print 'Avg Pts', scorer_f.score_model(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So in conclusion, it looks like the highest accuracy is .708, which belongs to the V1 variables with everything\n",
    "#THe highest points is 86.2, which is V2 variables with nothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
